
<HTML>
<HEAD>
<meta http-equiv="content-type" content="text/html; charset=windows-1252">
<link href="https://www.cs.hku.hk/images/hku.png" rel="shortcut icon" />
<title>Lingpeng Kong</title>
    <link rel="stylesheet" href="inde_files/dyerlike.css"/>
    <link rel="stylesheet" href="inde_files/pygments.css"/>
</HEAD>
<BODY>
<header>
<nav>
<ul>
<ul>
    <li><a href="index.html">Home</a></li>
    <li><a href="https://nlp.cs.hku.hk/">Group</a></li>
    <li><a href="publications.html">Publications</a></li>
    <li><a href="mailto:lpk@cs.hku.hk">Contact</a></li> 
</ul>

</ul>
</nav>
<h2>Lingpeng Kong</h2> 
</header>
<!--
<section>
<h2> Preprints </h2>
<ul>
</ul>
</section>
-->
<section>
<h2> Publications</h2>
<br>
<h3>2021</h3>
<ul>
<li>Dani Yogatama, Cyprien de Masson d'Autume, Lingpeng Kong, <a href=https://https://ikekonglp.github.io/publications.html>Adaptive Semiparametric Language Models</a>, <em>Transactions of the Association for Computational Linguistics</em> <b>(TACL)</b>, 2021</li>
<li>Hao Peng, Nikolaos Pappas, Dani Yogatama, Roy Schwartz, Noah Smith, Lingpeng Kong, <a href=https://https://ikekonglp.github.io/publications.html>Random Feature Attention</a>,  <em>In International Conference on Learning Representations</em> <b>(ICLR 2021)</b>, Vienna, Austria, 2021.5 <b>[Spotlight]</b></li>
</ul>
<h3>2020</h3>
<ul>
<li>Adhiguna Kuncoro*, Lingpeng Kong*, Daniel Fried*, Dani Yogatama, Laura Rimell, Chris Dyer, Phil Blunsom, <a href=https://arxiv.org/pdf/2005.13482.pdf>Syntactic Structure Distillation Pretraining For Bidirectional Encoders</a>, <em>Transactions of the Association for Computational Linguistics</em> <b>(TACL)</b>, 2020.9</li>
<li>Lei Yu, Laurent Sartran, Wojciech Stokowiec, Wang Ling, Lingpeng Kong, Phil Blunsom, Chris Dyer, <a href=https://arxiv.org/pdf/1910.00553.pdf>Better Document-level Machine
Translation with Bayes' Rule</a>, <em>Transactions of the Association for Computational Linguistics</em> <b>(TACL)</b>, 2020.4</li>
<li>Lingpeng Kong, Cyprien de Masson d'Autume, Wang Ling, Lei Yu, Zihang Dai, Dani Yogatama, <a href=https://arxiv.org/abs/1910.08350.pdf>A Mutual Information Maximization Perspective of Language Representation Learning</a>, <em>In International Conference on Learning Representations</em> <b>(ICLR 2020)</b>, Ethiopia, 2020.4 <b>[Spotlight]</b></li>
</ul>
<h3>2019</h3>
<ul>
<li>Cyprien de Masson d'Autume, Sebastian Ruder, Lingpeng Kong, Dani Yogatama, <a href=https://arxiv.org/pdf/1906.01076.pdf> Episodic Memory in Lifelong Language Learning</a>, In <em>Advances in Neural Information Processing Systems</em> <b>(NeurIPS 2019)</b>, Vancouver, Canada, 2019.11</li>
<li>Lingpeng Kong, Gabor Melis, Wang Ling, Lei Yu, Dani Yogatama, <a href=https://arxiv.org/pdf/1901.09296.pdf>Variational Smoothing in Recurrent Neural Network Language Models</a>, In <em>International Conference on Learning Representations</em> <b>(ICLR 2019)</b>, New Orleans, Louisiana, 2019.5</li>
<li>Dani Yogatama, Cyprien de Masson d'Autume, Jerome Connor, Tomas Kocisky, Mike Chrzanowski, Lingpeng Kong, Angeliki Lazaridou, Wang Ling, Lei Yu, Chris Dyer, Phil Blunsom, <a href=https://arxiv.org/pdf/1901.11373.pdf>Learning and Evaluating General Linguistic Intelligence</a>, <em>arXiv:1901.11373</em>, 2019.2</li>
</ul>
<h3>2018</h3>
<ul>
<li> Jiangtao Feng, Lingpeng Kong, Po-Sen Huang, Chong Wang, Da Huang, Jiayuan Mao, Kan Qiao, Dengyong Zhou, <a href=https://arxiv.org/pdf/1811.02172.pdf> Neural Phrase-to-Phrase Machine Translation</a>, <em>arXiv:1811.02172</em>, 2018.11</li>
<li> Lei Yu, Cyprien de Masson d'Autume, Chris Dyer, Phil Blunsom, Lingpeng Kong, Wang Ling, <a href=https://arxiv.org/pdf/1811.10475.pdf>Sentence Encoding with Tree-constrained Relation Networks</a>, <em>arXiv:1811.10475</em>, 2018.11</li>
</ul>
<h3> 2017 </h3>
<ul>
<li> Lingpeng Kong, <a href="thesis_draft.pdf">Neural Representation Learning in Linguistic Structured Prediction</a>, Ph.D. thesis, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, 2017.9</li>
<li> Hao Tang, Liang Lu, Lingpeng Kong, Kevin Gimpel, Karen Livescu, Chris Dyer, Noah A. Smith, Steve Renals, <a href="https://arxiv.org/abs/1708.00531">End-to-End Neural Segmental Models for Speech Recognition</a>, <em>IEEE Journal of Selected Topics in Signal Processing</em>, 2017.8</li>
<li> Liang Lu, Lingpeng Kong, Chris Dyer, Noah A. Smith, <a href="https://arxiv.org/abs/1702.06378">Multi-task Learning with CTC and Segmental CRF for Speech Recognition</a>, In <em>Proceedings of the Annual Conference of the International Speech Communication Association</em> <b>(INTERSPEECH 2017)</b>, Stockholm, Sweden, 2017.8</li>
<li> Adhiguna Kuncoro, Miguel Ballesteros, Lingpeng Kong, Chris Dyer, Graham Neubig, Noah A. Smith, <a href="https://arxiv.org/abs/1611.05774">What Do Recurrent Neural Network Grammars Learn About Syntax?</a>, In <em>Proceedings of the Conference of the European Chapter of the Association for Computational Linguistics</em> <b>(EACL 2017)</b>, Valencia, Spain, 2017.4 <b>[Outstanding Paper Award]</b></li>
<li> Chris Alberti, Daniel Andor, Ivan Bogatyy, Michael Collins, Dan Gillick, Lingpeng Kong, Terry Koo, Ji Ma, Mark Omernick, Slav Petrov, Chayut Thanapirom, Zora Tung, David Weiss, <a href="https://arxiv.org/abs/1703.04929">SyntaxNet Models for the CoNLL 2017 Shared Task</a>, <em>arXiv:1703.04929</em>, 2017.3</li>
<li> Lingpeng Kong, Chris Alberti, Daniel Andor, Ivan Bogatyy, David Weiss, <a href="https://arxiv.org/abs/1703.04474">DRAGNN: A Transition-based Framework for Dynamically Connected Neural Networks</a>, <em>arXiv:1703.04474</em>, 2017.3</li>
<li> Graham Neubig, Chris Dyer, Yoav Goldberg, Austin Matthews, Waleed Ammar, Antonios Anastasopoulos, Miguel Ballesteros, David Chiang, Daniel Clothiaux, Trevor Cohn, Kevin Duh, Manaal Faruqui, Cynthia Gan, Dan Garrette, Yangfeng Ji, Lingpeng Kong, Adhiguna Kuncoro, Gaurav Kumar, Chaitanya Malaviya, Paul Michel, Yusuke Oda, Matthew Richardson, Naomi Saphra, Swabha Swayamdipta, Pengcheng Yin, <a href="https://arxiv.org/abs/1701.03980">DyNet: The Dynamic Neural Network Toolkit</a>, <em>arXiv:1701.03980</em>, 2017.1</li>
</ul>
<h3>2016</h3>
<ul>
<li> Adhiguna Kuncoro, Miguel Ballesteros, Lingpeng Kong, Chris Dyer, and Noah A. Smith, <a href="https://arxiv.org/abs/1609.07561">Distilling an Ensemble of Greedy Dependency Parsers into One MST Parser</a>, In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing</em> <b>(EMNLP 2016)</b>, Austin, TX, 2016.11</li>
<li> Liang Lu*, Lingpeng Kong*, Chris Dyer, Noah A. Smith, Steve Renals, <a href="http://arxiv.org/abs/1603.00223">Segmental Recurrent Neural Networks for End-to-end Speech Recognition</a>, In <em>Proceedings of the Annual Conference of the International Speech Communication Association</em> <b>(INTERSPEECH 2016)</b>, San Francisco, California, 2016.9 (*equal contribution)</li>
<li> Lingpeng Kong, Chris Dyer, and Noah A. Smith, <a href="http://arxiv.org/abs/1511.06018">Segmental Recurrent Neural Networks</a>, In <em>International Conference on Learning Representations</em> <b>(ICLR 2016)</b>, San Juan, Puerto Rico, 2016.5</li>
<li> Yangfeng Ji, Trevor Cohn, Lingpeng Kong, Chris Dyer, Jacob Eisenstein, <a href="http://arxiv.org/abs/1511.03962">Document Context Language Models</a>, In <em>International Conference on Learning Representations</em> <b>(ICLR 2016 Workshop Track)</b>, San Juan, Puerto Rico, 2016.5</li>
</ul>
<h3>2015</h3>
<ul>
<li> Dani Yogatama, Lingpeng Kong, and Noah A. Smith, <a href="paper/emnlp15.pdf">Bayesian Optimization of Text Representations</a>, In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing</em> <b>(EMNLP 2015)</b>, Lisboa, Portugal, 2015.9</li> 
<li> Ting-Hao (Kenneth) Huang, Yun-Nung Chen, and Lingpeng Kong, <a href="paper/sighan15.pdf">ACBiMA: Advanced Chinese Bi-Character Word Morphological Analyzer</a>, In <em>Proceedings of The 8th SIGHAN Workshop on Chinese Language Processing</em> <b>(SIGHAN-8)</b>, Beijing, China, 2015.7 [<a href="http://acbima.org/">software</a>]</li>
<li> Lingpeng Kong, Alexander M. Rush, and Noah A. Smith, <a href="paper/naacl15.pdf">Transforming Dependencies into Phrase Structures</a>, In <em>Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics - Human Language Technologies</em> <b>(NAACL-HLT 2015)</b>, Denver, CO, 2015.5 [<a href="https://github.com/ikekonglp/PAD">software</a>]</li>
</ul>
<h3>2014</h3>
<ul>
<li> Lingpeng Kong, Nathan Schneider, Swabha Swayamdipta, Archna Bhatia, Chris Dyer, and Noah A. Smith, <a href="paper/emnlp14a.pdf">A Dependency Parser for Tweets</a>, In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing</em> <b>(EMNLP 2014)</b>, Doha, Qatar, 2014.10  [<a href="material/tweeboparserpdf.pdf">slides</a>, <a href="http://www.ark.cs.cmu.edu/TweetNLP/">software</a>] </li>

<li> William Yang Wang, Lingpeng Kong, Kathryn Mazaitis, and William W. Cohen, <a href="paper/emnlp14b.pdf">Dependency Parsing for Weibo: An Efficient Probabilistic Logic Programming Approach</a>, In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing</em> <b>(EMNLP 2014)</b>, Doha, Qatar, 2014.10 </li>
<li>Lingpeng Kong, Noah A. Smith, <a href="http://arxiv.org/abs/1404.4314">An Empirical Comparison of Parsing Methods for Stanford Dependencies</a>, <em>arXiv:1404.4314</em>, 2014.04 </li>
</ul>
<h3>2011</h3>
<ul>
<li>Lingpeng Kong, Likun Qiu, <a href="paper/ialp11a.pdf">Formalization and Rules for Recognition of Satirical Irony</a>, In <em>Proceedings of the International Conference on Asian Language Processing</em>, Penang, Malaysia, 2011.11 </li>

<li>Likun Qiu, Lei Wu, Changjian Hu, Kai Zhao, Lingpeng Kong, <a href="paper/ialp11b.pdf">Improving Chinese Dependency Parsing with Self-Disambiguating Patterns</a>, In <em>Proceedings of the International Conference on Asian Language Processing</em>, Penang, Malaysia, 2011.11 </li></ul>

</ul>

</section>
</body>
</html>

