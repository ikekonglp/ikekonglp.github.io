
<HTML>
<HEAD>
<meta http-equiv="content-type" content="text/html; charset=utf-8">
<link href="https://www.cs.hku.hk/images/hku.png" rel="shortcut icon" />
<title>Lingpeng Kong</title>
    <link rel="stylesheet" href="inde_files/dyerlike.css"/>
    <link rel="stylesheet" href="inde_files/pygments.css"/>
</HEAD>
<BODY>
<header>
<nav>
<ul>
<ul>
    <li><a href="index.html">Home</a></li>
    <li><a href="https://nlp.cs.hku.hk/">Group</a></li>
    <li><a href="publications.html">Publications</a></li>
    <li><a href="mailto:lpk@cs.hku.hk">Contact</a></li> 
</ul>

</ul>
</nav>
<h2>Lingpeng Kong</h2> 
</header>

<section>
<h2> Working Drafts </h2>
<br>
Please send us an email if you have any suggestions regarding the following working drafts. We will buy you a cup of thank you <a href="https://www.naixue.com/">Naixue (奈雪)</a> or <a href="https://www.heytea.com/">Hey Tea (喜茶)</a> for help improving the work :)
<ul>
	<li> Jiacheng Ye, Jiahui Gao, Qintong Li, Hang Xu, Jiangtao Feng, Zhiyong Wu, Tao Yu, and Lingpeng Kong, <strong><a href=https://arxiv.org/abs/2202.07922> ZeroGen: Efficient Zero-shot Learning via Dataset Generation</a></strong>, <em>arXiv:2202.07922</em>, 2022.02</li>

	<li> Lin Zheng, Huijie Pan, and Lingpeng Kong, <strong><a href=https://arxiv.org/abs/2110.02453> Ripple Attention for Visual Perception with Sub-quadratic Complexity</a></strong>, <em>arXiv:2110.02453</em>, 2021.10</li>
</ul>
</section>

<section>
<h2> Publications</h2>
<br>
<h3>2022</h3>
<ul>
<li><a href="https://prange.jakob.georgetown.domains/">Jakob Prange</a>, <a href="http://people.cs.georgetown.edu/nschneid/">Nathan Schneider</a>, and Lingpeng Kong, <strong><a href="https://arxiv.org/pdf/2112.07874.pdf">Linguistic Frameworks Go Toe-to-Toe at Neuro-Symbolic Language Modeling</a></strong>, In <em>Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics</em> <b>(NAACL 2022)</b>, 2022.7 </li>

<li><a href="https://qtli.github.io/">Qintong Li</a>, <a href="https://lipiji.com/">Piji Li</a>, <a href="https://scholar.google.com/citations?user=aSJcgQMAAAAJ">Wei Bi</a>, <a href="https://ir.sdu.edu.cn/~zhaochunren/">Zhaochun Ren</a>, <a href="https://scholar.google.com.hk/citations?user=oKbXK7EAAAAJ">Yuxuan Lai</a>, and Lingpeng Kong, <strong><a href="">Event Transition Planning for Open-ended Text Generation</a></strong>, In <em>Findings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2022 Findings)</b>, 2022.5 </li>

<li><a href="https://lividwo.github.io/zywu.github.io/">Zhiyong Wu</a>, <a href="https://scholar.google.com/citations?user=aSJcgQMAAAAJ">Wei Bi</a>, <a href="https://lixiang3776.github.io/">Xiang Li</a>, Lingpeng Kong, and <a href="https://www.cs.hku.hk/people/academic-staff/kao">Ben Kao</a>, <strong><a href="">Lexical Knowledge Internalization for Neural Dialog Generation</a></strong>, In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2022)</b>, 2022.5 </li>

<li><a href="https://homes.cs.washington.edu/~hapeng/">Hao Peng</a>, <a href="https://homes.cs.washington.edu/~jkasai/">Jungo Kasai</a>, <a href="https://nik0spapp.github.io/">Nikolaos Pappas</a>, <a href="https://dyogatama.github.io/">Dani Yogatama</a>, <a href="https://zhaofengwu.github.io/">Zhaofeng Wu</a>, Lingpeng Kong, <a href="https://schwartz-lab-huji.github.io/">Roy Schwartz</a>, and <a href="https://homes.cs.washington.edu/~nasmith/">Noah A. Smith</a>, <strong><a href="https://arxiv.org/abs/2110.02488">ABC: Attention with Bounded-memory Control</a></strong>, In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2022)</b>, 2022.5 </li>

<li> <a href="https://github.com/Doraemonzzz">Zhen Qin</a>, <a href="https://cs.anu.edu.au/people/weixuan-sun">Weixuan Sun</a>, <a href="https://www.researchgate.net/profile/Hui-Deng-24">Hui Deng</a>, <a href="https://dxli94.github.io/">Dongxu Li</a>, <a href="https://www.zhihu.com/people/wei-yun-shen">Yunshen Wei</a>, <a href="https://github.com/lkjx82">Baohong Lv</a>, <a href="https://yan-junjie.github.io/">Junjie Yan</a>, Lingpeng Kong, and <a href="https://yiranzhong.com/">Yiran Zhong</a>, <strong><a href="https://openreview.net/pdf?id=Bl8CQrx2Up4">cosFormer: Rethinking Softmax In Attention</a></strong>,  In <em>International Conference on Learning Representations</em> <b>(ICLR 2022)</b>, 2022.4 </li>

<li> <a href="https://han-shi.github.io/">Han Shi</a>*, <a href="https://sumilergao.github.io/jiahuig.hku/">Jiahui Gao</a>*, <a href="https://scholar.google.com/citations?user=J_8TX6sAAAAJ&hl=en">Hang Xu</a>, <a href="https://lemondan.github.io/">Xiaodan Liang</a>, <a href="https://www.ee.columbia.edu/~zgli/">Zhenguo Li</a>, Lingpeng Kong, <a href="https://saasweb.hku.hk/staff/smslee/">Stephen M. S. Lee</a>, and <a href="https://www.cse.ust.hk/~jamesk/">James Kwok</a>, <strong><a href="https://openreview.net/pdf?id=dUV91uaXm3">Revisiting Over-smoothing in BERT from the Perspective of Graph</a></strong>,  In <em>International Conference on Learning Representations</em> <b>(ICLR 2022)</b>, 2022.4 <b>[Spotlight]</b></li>

</ul>
<h3>2021</h3>
<ul>
<li><a href="https://lzhengisme.github.io/">Lin Zheng</a>, <a href="https://lividwo.github.io/zywu.github.io/">Zhiyong Wu</a> and Lingpeng Kong, <strong><a href="https://arxiv.org/abs/2105.14850">Cascaded Head-colliding Attention</a></strong>, In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2021)</b>, 2021.8 </li>
<li><a href="https://lividwo.github.io/zywu.github.io/">Zhiyong Wu</a>, Lingpeng Kong, <a href="https://scholar.google.com/citations?user=aSJcgQMAAAAJ">Wei Bi</a>, <a href="https://lixiang3776.github.io/">Xiang Li</a> and <a href="https://www.cs.hku.hk/people/academic-staff/kao">Ben Kao</a>, <strong><a href="https://arxiv.org/abs/2105.14462">Good for Misconceived Reasons: An Empirical Revisiting on the Need for Visual Context in Multimodal Machine Translation</a></strong>, In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2021)</b>, 2021.8 </li>
<li><a href="https://dyogatama.github.io/">Dani Yogatama</a>, <a href="https://scholar.google.com/citations?user=vcmTSYEAAAAJ">Cyprien de Masson d'Autume</a>, and Lingpeng Kong, <strong><a href=https://dyogatama.github.io/publications_files/Yogatama+etal_TACL2021.pdf>Adaptive Semiparametric Language Models</a></strong>, <em>Transactions of the Association for Computational Linguistics</em> <b>(TACL)</b>, 2021</li>
<li><a href="https://homes.cs.washington.edu/~hapeng/">Hao Peng</a>, <a href="https://nik0spapp.github.io/">Nikolaos Pappas</a>, <a href="https://dyogatama.github.io/">Dani Yogatama</a>, <a href="https://schwartz-lab-huji.github.io/">Roy Schwartz</a>, <a href="https://homes.cs.washington.edu/~nasmith/">Noah A. Smith</a>, and Lingpeng Kong, <strong><a href=https://openreview.net/forum?id=QtTKTdVrFBB>Random Feature Attention</a></strong>,  In <em>International Conference on Learning Representations</em> <b>(ICLR 2021)</b>, Vienna, Austria, 2021.5 <b>[Spotlight]</b></li>
</ul>
<h3>2020</h3>
<ul>
<li><a href="https://www.cs.cmu.edu/~akuncoro/">Adhiguna Kuncoro</a>*, Lingpeng Kong*, <a href="https://dpfried.github.io/">Daniel Fried</a>*, <a href="https://dyogatama.github.io/">Dani Yogatama</a>, <a href="https://scholar.google.com/citations?user=bMTBja0AAAAJ&hl=en">Laura Rimell</a>, <a href="http://www.cs.cmu.edu/~cdyer/">Chris Dyer</a>, and <a href="https://www.cs.ox.ac.uk/people/phil.blunsom/">Phil Blunsom</a>, <strong><a href=https://arxiv.org/pdf/2005.13482.pdf>Syntactic Structure Distillation Pretraining For Bidirectional Encoders</a></strong>, <em>Transactions of the Association for Computational Linguistics</em> <b>(TACL)</b>, 2020.9</li>
<li><a href="https://www.cs.ox.ac.uk/people/lei.yu/">Lei Yu</a>, Laurent Sartran, Wojciech Stokowiec, <a href="https://www.cs.cmu.edu/~lingwang/">Wang Ling</a>, Lingpeng Kong, <a href="https://www.cs.ox.ac.uk/people/phil.blunsom/">Phil Blunsom</a>, and <a href="http://www.cs.cmu.edu/~cdyer/">Chris Dyer</a>, <strong><a href=https://arxiv.org/pdf/1910.00553.pdf>Better Document-level Machine Translation with Bayes' Rule</a></strong>, <em>Transactions of the Association for Computational Linguistics</em> <b>(TACL)</b>, 2020.4</li>
<li>Lingpeng Kong, <a href="https://scholar.google.com/citations?user=vcmTSYEAAAAJ">Cyprien de Masson d'Autume</a>, <a href="https://www.cs.cmu.edu/~lingwang/">Wang Ling</a>, <a href="https://www.cs.ox.ac.uk/people/lei.yu/">Lei Yu</a>, <a href="https://zihangdai.github.io/">Zihang Dai</a>, and <a href="https://dyogatama.github.io/">Dani Yogatama</a>, <strong><a href=https://arxiv.org/abs/1910.08350.pdf>A Mutual Information Maximization Perspective of Language Representation Learning</a></strong>, In <em>International Conference on Learning Representations</em> <b>(ICLR 2020)</b>, Ethiopia, 2020.4 <b>[Spotlight]</b></li>
</ul>
<h3>2019</h3>
<ul>
<li><a href="https://scholar.google.com/citations?user=vcmTSYEAAAAJ">Cyprien de Masson d'Autume</a>, <a href="https://ruder.io/">Sebastian Ruder</a>, Lingpeng Kong, and <a href="https://dyogatama.github.io/">Dani Yogatama</a>, <strong><a href=https://arxiv.org/pdf/1906.01076.pdf> Episodic Memory in Lifelong Language Learning</a></strong>, In <em>Advances in Neural Information Processing Systems</em> <b>(NeurIPS 2019)</b>, Vancouver, Canada, 2019.11</li>
<li>Lingpeng Kong, Gabor Melis, <a href="https://www.cs.cmu.edu/~lingwang/">Wang Ling</a>, <a href="https://www.cs.ox.ac.uk/people/lei.yu/">Lei Yu</a>, and <a href="https://dyogatama.github.io/">Dani Yogatama</a>, <strong><a href=https://arxiv.org/pdf/1901.09296.pdf>Variational Smoothing in Recurrent Neural Network Language Models</a></strong>, In <em>International Conference on Learning Representations</em> <b>(ICLR 2019)</b>, New Orleans, Louisiana, 2019.5</li>
<li><a href="https://dyogatama.github.io/">Dani Yogatama</a>, <a href="https://scholar.google.com/citations?user=vcmTSYEAAAAJ">Cyprien de Masson d'Autume</a>, Jerome Connor, <a href="http://www.tomas.kocisky.eu/">Tomas Kocisky</a>, Mike Chrzanowski, Lingpeng Kong, <a href="http://angelikilazaridou.github.io/">Angeliki Lazaridou</a>, <a href="https://www.cs.cmu.edu/~lingwang/">Wang Ling</a>, <a href="https://www.cs.ox.ac.uk/people/lei.yu/">Lei Yu</a>, <a href="http://www.cs.cmu.edu/~cdyer/">Chris Dyer</a>, and <a href="https://www.cs.ox.ac.uk/people/phil.blunsom/">Phil Blunsom</a>, <strong><a href=https://arxiv.org/pdf/1901.11373.pdf>Learning and Evaluating General Linguistic Intelligence</a></strong>, <em>arXiv:1901.11373</em>, 2019.2</li>
</ul>
<h3>2018</h3>
<ul>
<li> Jiangtao Feng, Lingpeng Kong, <a href="https://posenhuang.github.io/">Po-Sen Huang</a>, <a href="https://chongw.github.io/">Chong Wang</a>, Da Huang, <a href="https://jiayuanm.com/">Jiayuan Mao</a>, Kan Qiao, and <a href="https://dennyzhou.github.io/">Dengyong Zhou</a>, <strong><a href=https://arxiv.org/pdf/1811.02172.pdf> Neural Phrase-to-Phrase Machine Translation</a></strong>, <em>arXiv:1811.02172</em>, 2018.11</li>
<li> <a href="https://www.cs.ox.ac.uk/people/lei.yu/">Lei Yu</a>, <a href="https://scholar.google.com/citations?user=vcmTSYEAAAAJ">Cyprien de Masson d'Autume</a>, <a href="http://www.cs.cmu.edu/~cdyer/">Chris Dyer</a>, <a href="https://www.cs.ox.ac.uk/people/phil.blunsom/">Phil Blunsom</a>, Lingpeng Kong, and <a href="https://www.cs.cmu.edu/~lingwang/">Wang Ling</a>, <strong><a href=https://arxiv.org/pdf/1811.10475.pdf>Sentence Encoding with Tree-constrained Relation Networks</a></strong>, <em>arXiv:1811.10475</em>, 2018.11</li>
</ul>
<h3> 2017 </h3>
<ul>
<li> Lingpeng Kong, <strong><a href="thesis_draft.pdf">Neural Representation Learning in Linguistic Structured Prediction</a></strong>, Ph.D. thesis, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, 2017.9</li>
<li> <a href="http://people.csail.mit.edu/haotang/">Hao Tang</a>, Liang Lu, Lingpeng Kong, <a href="https://home.ttic.edu/~kgimpel/">Kevin Gimpel</a>, <a href="https://home.ttic.edu/~klivescu/">Karen Livescu</a>, <a href="http://www.cs.cmu.edu/~cdyer/">Chris Dyer</a>, <a href="https://homes.cs.washington.edu/~nasmith/">Noah A. Smith</a>, and <a href="https://www.inf.ed.ac.uk/people/staff/Stephen_Renals.html">Steve Renals</a>, <strong><a href="https://arxiv.org/abs/1708.00531">End-to-End Neural Segmental Models for Speech Recognition</a></strong>, <em>IEEE Journal of Selected Topics in Signal Processing</em>, 2017.8</li>
<li> Liang Lu, Lingpeng Kong, <a href="http://www.cs.cmu.edu/~cdyer/">Chris Dyer</a>, and <a href="https://homes.cs.washington.edu/~nasmith/">Noah A. Smith</a>, <strong><a href="https://arxiv.org/abs/1702.06378">Multi-task Learning with CTC and Segmental CRF for Speech Recognition</a></strong>, In <em>Proceedings of the Annual Conference of the International Speech Communication Association</em> <b>(INTERSPEECH 2017)</b>, Stockholm, Sweden, 2017.8</li>
<li> <a href="https://www.cs.cmu.edu/~akuncoro/">Adhiguna Kuncoro</a>, <a href="http://miguelballesteros.com/">Miguel Ballesteros</a>, Lingpeng Kong, <a href="http://www.cs.cmu.edu/~cdyer/">Chris Dyer</a>, <a href="http://www.phontron.com/">Graham Neubig</a>, and <a href="https://homes.cs.washington.edu/~nasmith/">Noah A. Smith</a>, <strong><a href="https://arxiv.org/abs/1611.05774">What Do Recurrent Neural Network Grammars Learn About Syntax?</a></strong>, In <em>Proceedings of the Conference of the European Chapter of the Association for Computational Linguistics</em> <b>(EACL 2017)</b>, Valencia, Spain, 2017.4 <b>[Outstanding Paper Award]</b></li>
<li> Chris Alberti, Daniel Andor, Ivan Bogatyy, <a href="http://www.cs.columbia.edu/~mcollins/">Michael Collins</a>, Dan Gillick, Lingpeng Kong, <a href="https://people.csail.mit.edu/maestro/">Terry Koo</a>, Ji Ma, Mark Omernick, <a href="https://www.petrovi.de/">Slav Petrov</a>, Chayut Thanapirom, Zora Tung, and David Weiss, <strong><a href="https://arxiv.org/abs/1703.04929">SyntaxNet Models for the CoNLL 2017 Shared Task</a></strong>, <em>arXiv:1703.04929</em>, 2017.3</li>
<li> Lingpeng Kong, Chris Alberti, Daniel Andor, Ivan Bogatyy, and David Weiss, <strong><a href="https://arxiv.org/abs/1703.04474">DRAGNN: A Transition-based Framework for Dynamically Connected Neural Networks</a></strong>, <em>arXiv:1703.04474</em>, 2017.3</li>
<li> <a href="http://www.phontron.com/">Graham Neubig</a>, <a href="http://www.cs.cmu.edu/~cdyer/">Chris Dyer</a>, <a href="https://u.cs.biu.ac.il/~yogo/">Yoav Goldberg</a>, Austin Matthews, <a href="https://wammar.github.io/">Waleed Ammar</a>, Antonios Anastasopoulos, <a href="http://miguelballesteros.com/">Miguel Ballesteros</a>, <a href="https://www3.nd.edu/~dchiang/">David Chiang</a>, Daniel Clothiaux, <a href="https://people.eng.unimelb.edu.au/tcohn/">Trevor Cohn</a>, <a href="http://cs.jhu.edu/~kevinduh/">Kevin Duh</a>, <a href="https://www.manaalfaruqui.com/">Manaal Faruqui</a>, Cynthia Gan, <a href="http://www.dhgarrette.com/">Dan Garrette</a>, <a href="https://yangfengji.net/">Yangfeng Ji</a>, Lingpeng Kong, <a href="https://www.cs.cmu.edu/~akuncoro/">Adhiguna Kuncoro</a>, Gaurav Kumar, Chaitanya Malaviya, Paul Michel, Yusuke Oda, Matthew Richardson, Naomi Saphra, <a href="https://swabhs.com/">Swabha Swayamdipta</a>, and <a href="http://pcyin.me/">Pengcheng Yin</a>, <strong><a href="https://arxiv.org/abs/1701.03980">DyNet: The Dynamic Neural Network Toolkit</a></strong>, <em>arXiv:1701.03980</em>, 2017.1</li>
</ul>
<h3>2016</h3>
<ul>
<li> <a href="https://www.cs.cmu.edu/~akuncoro/">Adhiguna Kuncoro</a>, <a href="http://miguelballesteros.com/">Miguel Ballesteros</a>, Lingpeng Kong, <a href="http://www.cs.cmu.edu/~cdyer/">Chris Dyer</a>, and <a href="https://homes.cs.washington.edu/~nasmith/">Noah A. Smith</a>, <strong><a href="https://arxiv.org/abs/1609.07561">Distilling an Ensemble of Greedy Dependency Parsers into One MST Parser</a></strong>, In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing</em> <b>(EMNLP 2016)</b>, Austin, TX, 2016.11</li>
<li> Liang Lu*, Lingpeng Kong*, <a href="http://www.cs.cmu.edu/~cdyer/">Chris Dyer</a>, <a href="https://homes.cs.washington.edu/~nasmith/">Noah A. Smith</a>, and Steve Renals, <strong><a href="http://arxiv.org/abs/1603.00223">Segmental Recurrent Neural Networks for End-to-end Speech Recognition</a></strong>, In <em>Proceedings of the Annual Conference of the International Speech Communication Association</em> <b>(INTERSPEECH 2016)</b>, San Francisco, California, 2016.9 (*equal contribution)</li>
<li> Lingpeng Kong, <a href="http://www.cs.cmu.edu/~cdyer/">Chris Dyer</a>, and <a href="https://homes.cs.washington.edu/~nasmith/">Noah A. Smith</a>, <strong><a href="http://arxiv.org/abs/1511.06018">Segmental Recurrent Neural Networks</a></strong>, In <em>International Conference on Learning Representations</em> <b>(ICLR 2016)</b>, San Juan, Puerto Rico, 2016.5</li>
<li> <a href="https://yangfengji.net/">Yangfeng Ji</a>, <a href="https://people.eng.unimelb.edu.au/tcohn/">Trevor Cohn</a>, Lingpeng Kong, <a href="http://www.cs.cmu.edu/~cdyer/">Chris Dyer</a>, and <a href="https://jacobeisenstein.github.io/">Jacob Eisenstein</a>, <strong><a href="http://arxiv.org/abs/1511.03962">Document Context Language Models</a></strong>, In <em>International Conference on Learning Representations</em> <b>(ICLR 2016 Workshop Track)</b>, San Juan, Puerto Rico, 2016.5</li>
</ul>
<h3>2015</h3>
<ul>
<li> <a href="https://dyogatama.github.io/">Dani Yogatama</a>, Lingpeng Kong, and <a href="https://homes.cs.washington.edu/~nasmith/">Noah A. Smith</a>, <strong><a href="paper/emnlp15.pdf">Bayesian Optimization of Text Representations</a></strong>, In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing</em> <b>(EMNLP 2015)</b>, Lisboa, Portugal, 2015.9</li> 
<li> <a href="https://crowd.ist.psu.edu/">Ting-Hao (Kenneth) Huang</a>, <a href="https://www.csie.ntu.edu.tw/~yvchen/">Yun-Nung Chen</a>, and Lingpeng Kong, <strong><a href="paper/sighan15.pdf">ACBiMA: Advanced Chinese Bi-Character Word Morphological Analyzer</a></strong>, In <em>Proceedings of The 8th SIGHAN Workshop on Chinese Language Processing</em> <b>(SIGHAN-8)</b>, Beijing, China, 2015.7 [<a href="http://acbima.org/">software</a>]</li>
<li> Lingpeng Kong, <a href="http://rush-nlp.com/">Alexander M. Rush</a>, and <a href="https://homes.cs.washington.edu/~nasmith/">Noah A. Smith</a>, <strong><a href="paper/naacl15.pdf">Transforming Dependencies into Phrase Structures</a></strong>, In <em>Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics - Human Language Technologies</em> <b>(NAACL-HLT 2015)</b>, Denver, CO, 2015.5 [<a href="https://github.com/ikekonglp/PAD">software</a>]</li>
</ul>
<h3>2014</h3>
<ul>
<li> Lingpeng Kong, <a href="http://people.cs.georgetown.edu/nschneid/">Nathan Schneider</a>, <a href="https://swabhs.com/">Swabha Swayamdipta</a>, Archna Bhatia, <a href="http://www.cs.cmu.edu/~cdyer/">Chris Dyer</a>, and <a href="https://homes.cs.washington.edu/~nasmith/">Noah A. Smith</a>, <strong><a href="paper/emnlp14a.pdf">A Dependency Parser for Tweets</a></strong>, In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing</em> <b>(EMNLP 2014)</b>, Doha, Qatar, 2014.10  [<a href="material/tweeboparserpdf.pdf">slides</a>, <a href="http://www.ark.cs.cmu.edu/TweetNLP/">software</a>] </li>

<li> <a href="https://sites.cs.ucsb.edu/~william/">William Yang Wang</a>, Lingpeng Kong, Kathryn Mazaitis, and <a href="http://www.cs.cmu.edu/~wcohen/">William W. Cohen</a>, <strong><a href="paper/emnlp14b.pdf">Dependency Parsing for Weibo: An Efficient Probabilistic Logic Programming Approach</a></strong>, In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing</em> <b>(EMNLP 2014)</b>, Doha, Qatar, 2014.10 </li>
<li>Lingpeng Kong and <a href="https://homes.cs.washington.edu/~nasmith/">Noah A. Smith</a>, <strong><a href="http://arxiv.org/abs/1404.4314">An Empirical Comparison of Parsing Methods for Stanford Dependencies</a></strong>, <em>arXiv:1404.4314</em>, 2014.04 </li>
</ul>
<h3>2011</h3>
<ul>
<li>Lingpeng Kong and Likun Qiu, <strong><a href="paper/ialp11a.pdf">Formalization and Rules for Recognition of Satirical Irony</a></strong>, In <em>Proceedings of the International Conference on Asian Language Processing</em>, Penang, Malaysia, 2011.11 </li>

<li>Likun Qiu, Lei Wu, Changjian Hu, Kai Zhao, and Lingpeng Kong, <strong><a href="paper/ialp11b.pdf">Improving Chinese Dependency Parsing with Self-Disambiguating Patterns</a></strong>, In <em>Proceedings of the International Conference on Asian Language Processing</em>, Penang, Malaysia, 2011.11 </li></ul>

</ul>

</section>
</body>
</html>

