
<HTML>
<HEAD>
<meta http-equiv="content-type" content="text/html; charset=utf-8">
<link href="https://www.cs.hku.hk/images/hku.png" rel="shortcut icon" />
<title>Lingpeng Kong</title>
    <link rel="stylesheet" href="inde_files/dyerlike.css"/>
    <link rel="stylesheet" href="inde_files/pygments.css"/>
</HEAD>
<BODY>
<header>
<nav>
<ul>
<ul>
    <li><a href="index.html">Home</a></li>
    <li><a href="https://nlp.cs.hku.hk/">Group</a></li>
    <li><a href="publications.html">Publications</a></li>
    <li><a href="mailto:lpk@cs.hku.hk">Contact</a></li>
</ul>

</ul>
</nav>
<h2>Lingpeng Kong</h2> 
</header>

<section>
<h2> Working Drafts </h2>
<br>
Please send us an email if you have any suggestions regarding the following working drafts. We will buy you a cup of thank you <a href="https://www.naixue.com/">Naixue (奈雪)</a> or <a href="https://www.heytea.com/">Hey Tea (喜茶)</a> for help improving the work :)
<ul>
    <li> Xueliang Zhao, Wenda Li, and Lingpeng Kong, <strong><a href="https://arxiv.org/abs/2305.16366">Decomposing the Enigma: Subgoal-based Demonstration Learning for Formal Theorem Proving</a></strong>, <em>arXiv:2305.16366</em>, 2023.5</li>

    <li> Chang Ma, Haiteng Zhao, Lin Zheng, Jiayi Xin, Qintong Li, Lijun Wu, Zhihong Deng, Yang Lu, Qi Liu, and Lingpeng Kong, <strong><a href="https://arxiv.org/abs/2302.12563"> Retrieved Sequence Augmentation for Protein Representation Learning</a></strong>, <em>arXiv:2302.12563</em>, 2023.2</li>

    <li> Lin Zheng, Jianbo Yuan, Lei Yu, and Lingpeng Kong, <strong><a href="https://arxiv.org/abs/2302.05737"> A Reparameterized Discrete Diffusion Model for Text Generation</a></strong>, <em>arXiv:2302.04542</em>, 2023.2</li>
</ul>
</section>

<section>
<h2> Publications</h2>
<br>

<h3>2023</h3>
<ul>
    <li> <a href="https://github.com/Doraemonzzz">Zhen Qin</a>, <a href="https://cs.anu.edu.au/people/weixuan-sun">Weixuan Sun</a>, <a href="https://dblp.org/pid/190/8790.html">Kaiyue Lu</a>, <a href="https://dxli94.github.io/">Dongxu Li</a>, Xiaodong Han, <a href="https://teacher.nwpu.edu.cn/en/daiyuchao.html">Yuchao Dai</a>, Lingpeng Kong, and <a href="https://yiranzhong.com/">Yiran Zhong</a>, <strong><a href="https://arxiv.org/abs/2307.09270">Linearized Relative Positional Encoding</a></strong>, In <em>Transactions on Machine Learning Research</em> <b>(TMLR)</b>, 2023</li>

    <li> <a href="https://scholar.google.com/citations?user=slwTiOUAAAAJ">Shuyang Jiang</a>, <a href="https://scholar.google.com/citations?user=19qq4hsAAAAJ">Jun Zhang</a>, <a href="https://jiangtaofeng.github.io/">Jiangtao Feng</a>, <a href="https://lzhengisme.github.io/">Lin Zheng</a>, and Lingpeng Kong, <strong><a href="">Attentive Multi-Layer Perceptron for Non-autoregressive Generation</a></strong>, In <em>Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases</em> <b>(ECML/PKDD 2023)</b>, Turin, Italy, 2023.9</li>

    <li><a href="https://cs.anu.edu.au/people/weixuan-sun">Weixuan Sun</a>, <a href="https://github.com/Doraemonzzz">Zhen Qin</a>, <a href="https://www.researchgate.net/profile/Hui-Deng-24">Hui Deng</a>, <a href="https://jytime.github.io/">Jianyuan Wang</a>, Yi Zhang, Kaihao Zhang, <a href="http://users.cecs.anu.edu.au/~nmb/">Nick Barnes</a>, <a href="https://cecas.clemson.edu/~stb/">Stan Birchfield</a>, Lingpeng Kong, and <a href="https://yiranzhong.com/">Yiran Zhong</a>, <strong><a href="https://arxiv.org/abs/2206.10552">Vicinity Vision Transformer</a></strong>, In <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> <b>(TPAMI)</b>, 2023 </li>

    <li><a href="https://lividwo.github.io/zywu.github.io/">Zhiyong Wu</a>*, <a href="https://scholar.google.com/citations?hl=en&user=7e_BZuYAAAAJ">Yaoxiang Wang</a>*, <a href="https://jiacheng-ye.github.io/">Jiacheng Ye</a>*, and Lingpeng Kong, <strong><a href="https://arxiv.org/abs/2212.10375">Self-adaptive In-context Learning</a></strong>, In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2023)</b>, Toronto, Canada, 2023.7 </li>

    <li><a href="https://qtli.github.io/">Qintong Li</a>, <a href="https://lividwo.github.io/zywu.github.io/">Zhiyong Wu</a>, Lingpeng Kong, and <a href="https://scholar.google.com/citations?user=aSJcgQMAAAAJ">Wei Bi</a>, <strong><a href="https://arxiv.org/abs/2212.09603">Explanation Regeneration via Information Bottleneck</a></strong>, In <em>Findings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2023 Findings)</b>, Toronto, Canada, 2023.7 </li>

    <li><a href="https://openreview.net/profile?id=~Fei_Yuan2">Fei Yuan</a>, <a href="https://scholar.google.com/citations?user=td9AYHQAAAAJ&hl=en">Yinquan Lu</a>, <a href="https://owennju.github.io/">Wenhao Zhu</a>, Lingpeng Kong, <a href="https://lileicc.github.io/">Lei Li</a>, and <a href="https://jingjingxu.com/">Jingjing Xu</a>, <strong><a href="https://arxiv.org/abs/2212.10551">Lego-MT: Learning Detachable Models for Massively Multilingual Machine Translation</a></strong>, In <em>Findings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2023 Findings)</b>, Toronto, Canada, 2023.7 </li>

    <li><a href="https://owennju.github.io/">Wenhao Zhu</a>, <a href="https://jingjingxu.com/">Jingjing Xu</a>, <a href="http://nlp.nju.edu.cn/huangsj/">Shujian Huang</a>, Lingpeng Kong, and <a href="https://cs.nju.edu.cn/chenjiajun/index_en.htm">Jiajun Chen</a>, <strong><a href="https://arxiv.org/abs/2306.06381">INK: Injecting kNN Knowledge in Nearest Neighbor Machine Translation</a></strong>, In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2023)</b>, Toronto, Canada, 2023.7 </li>

    <li><a href="https://scholar.google.com.hk/citations?user=O4ZaJ7QAAAAJ">Jiyue Jiang</a>, <a href="https://forence1999.github.io/">Sheng Wang</a>, <a href="https://qtli.github.io/">Qintong Li</a>, Lingpeng Kong, and <a href="https://i.cs.hku.hk/~cwu/">Chuan Wu</a>, <strong><a href="https://arxiv.org/abs/2305.08200">A Cognitive Stimulation Therapy Dialogue System with Multi-Source Knowledge Fusion for Elders with Cognitive Impairment</a></strong>, In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2023)</b>, Toronto, Canada, 2023.7 </li>

    <li><a href="https://scholar.google.com/citations?user=h-87C9cAAAAJ">Xueliang Zhao, <a href="https://dblp.org/pid/318/0986.html">Tingchen Fu</a>, <a href="https://lemaoliu.github.io/homepage/">Lemao Liu</a>, Lingpeng Kong, <a href="https://scholar.google.com/citations?user=Lg31AKMAAAAJ">Shuming Shi</a>, and <a href="https://scholar.google.com/citations?user=eLw6g-UAAAAJ">Rui Yan</a>, <strong><a href="">SORTIE: Dependency-Aware Symbolic Reasoning for Logical Data-to-text Generation</a></strong>, In <em>Findings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2023 Findings)</b>, Toronto, Canada, 2023.7 </li>

    <li> <a href="https://jiacheng-ye.github.io/">Jiacheng Ye</a>, <a href="https://lividwo.github.io/zywu.github.io/">Zhiyong Wu</a>, <a href="https://jiangtaofeng.github.io/">Jiangtao Feng</a>, <a href="https://taoyds.github.io">Tao Yu</a>, and Lingpeng Kong, <strong><a href="https://arxiv.org/abs/2302.05698">Compositional Exemplars for In-context Learning</a></strong>, In <em>Proceedings of the International Conference on Machine Learning</em> <b>(ICML 2023)</b>, Honolulu, Hawaii, 2023.7</li>

    <li> <a href="https://scholar.google.com/citations?user=19qq4hsAAAAJ">Jun Zhang</a>*, <a href="https://scholar.google.com/citations?user=slwTiOUAAAAJ">Shuyang Jiang</a>*, <a href="https://jiangtaofeng.github.io/">Jiangtao Feng</a>, <a href="https://lzhengisme.github.io/">Lin Zheng</a>, and Lingpeng Kong, <strong><a href="https://arxiv.org/abs/2210.07661"> CAB: Comprehensive Attention Benchmarking on Long Sequence Modeling</a></strong>, In <em>Proceedings of the International Conference on Machine Learning</em> <b>(ICML 2023)</b>, Honolulu, Hawaii, 2023.7</li>

    <li> <a href="https://scholar.google.com/citations?user=k6Q1mcoAAAAJ&hl=en">Xuyang Shen</a>, Dong Li, <a href="https://cn.linkedin.com/in/jinxing-zhou-26a77916b">Jinxing Zhou</a>, <a href="https://github.com/Doraemonzzz">Zhen Qin</a>, Bowen He, Xiaodong Han, Aixuan Li, <a href="https://teacher.nwpu.edu.cn/en/daiyuchao.html">Yuchao Dai</a>,  Lingpeng Kong, <a href="https://sites.google.com/view/meng-wang/home">Meng Wang</a>, and <a href="https://yiranzhong.com/">Yiran Zhong</a>, <strong><a href="https://arxiv.org/abs/2303.15616">Fine-grained Audible Video Description</a></strong>,  In <em>Proceedings of the Conference on Computer Vision and Pattern Recognition</em> <b>(CVPR 2023)</b>, Vancouver, Canada, 2023.6 </li>

     <li> <a href="https://lzhengisme.github.io/">Lin Zheng</a>, <a href="https://scholar.google.com/citations?user=B1EhbCsAAAAJ">Jianbo Yuan</a>, <a href="https://chongw.github.io/">Chong Wang</a>, and Lingpeng Kong, <strong><a href="https://arxiv.org/abs/2302.04542"> Efficient Attention via Control Variates</a></strong>, In <em>International Conference on Learning Representations</em> <b>(ICLR 2023)</b>, Kigali, Rwanda, 2023.5 <b>[Oral]</b></li>

    <li>  <a href="https://sumilergao.github.io/jiahuig.hku/">Jiahui Gao</a>, <a href="https://pipilurj.github.io/">Renjie Pi</a>, <a href="https://linyongver.github.io/yonglin.github.io/">Lin Yong</a>, <a href="https://xuhangcn.github.io/">Hang Xu</a>, <a href="https://jiacheng-ye.github.io/">Jiacheng Ye</a>, <a href="https://lividwo.github.io/zywu.github.io/">Zhiyong Wu</a>, <a href="https://scholar.google.com/citations?user=qd06pUgAAAAJ">Weizhong Zhang</a>, Xiaodan Liang, Zhenguo Li, and Lingpeng Kong, <strong><a href="https://openreview.net/pdf?id=h5OpjGd_lo6"> Self-Guided Noise-Free Data Generation for Efficient Zero-Shot Learning</a></strong>, In <em>International Conference on Learning Representations</em> <b>(ICLR 2023)</b>, Kigali, Rwanda, 2023.5 <b>[Spotlight]</b></li>

    <li> <a href="https://github.com/Doraemonzzz">Zhen Qin</a>, Xiaodong Han, <a href="https://cs.anu.edu.au/people/weixuan-sun">Weixuan Sun</a>, Bowen He, Dong Li, <a href="https://dxli94.github.io/">Dongxu Li</a>, <a href="https://teacher.nwpu.edu.cn/en/daiyuchao.html">Yuchao Dai</a>, Lingpeng Kong, and <a href="https://yiranzhong.com/">Yiran Zhong</a>, <strong><a href="https://openreview.net/pdf?id=IxmWsm4xrua"> Toeplitz Neural Network for Sequence Modeling</a></strong>, In <em>International Conference on Learning Representations</em> <b>(ICLR 2023)</b>, Kigali, Rwanda, 2023.5 <b>[Spotlight]</b></li>

    <li> <a href="https://summmeer.github.io/">Shansan Gong</a>, <a href="https://scholar.google.com/citations?user=BizedOAAAAAJ">Mukai Li</a>, <a href="https://jiangtaofeng.github.io/">Jiangtao Feng</a>, <a href="https://lividwo.github.io/zywu.github.io/">Zhiyong Wu</a>, and Lingpeng Kong, <strong><a href="https://arxiv.org/abs/2210.08933"> DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models</a></strong>, In <em>International Conference on Learning Representations</em> <b>(ICLR 2023)</b>, Kigali, Rwanda, 2023.5</li>

	<li> <a href="https://adacheng.github.io/">Sijie Chen</a>, <a href="https://lividwo.github.io/zywu.github.io/">Zhiyong Wu</a>, <a href="https://jiangjiechen.github.io/">Jiangjie Chen</a>, Zhixing Li, <a href="https://nlp.csai.tsinghua.edu.cn/~ly/">Yang Liu</a>, and Lingpeng Kong, <strong><a href="https://arxiv.org/abs/2211.11160"> Unsupervised Explanation Generation via Correct Instantiations</a></strong>, In <em>Proceedings of AAAI Conference on Artificial Intelligence</em> <b>(AAAI 2023)</b>, Washington, DC, 2023.2</li>
</ul>

<h3>2022</h3>
<ul>

<li> <a href="https://jiacheng-ye.github.io/">Jiacheng Ye</a>, <a href="https://sumilergao.github.io/jiahuig.hku/">Jiahui Gao</a>, <a href="https://lividwo.github.io/zywu.github.io/">Zhiyong Wu</a>, <a href="https://jiangtaofeng.github.io/">Jiangtao Feng</a>, <a href="https://taoyds.github.io">Tao Yu</a>, and Lingpeng Kong, <strong><a href="https://arxiv.org/abs/2210.12329"> ProGen: Progressive Zero-shot Dataset Generation via In-context Feedback</a></strong>, In <em>Findings of the Conference on Empirical Methods in Natural Language Processing</em> <b>(EMNLP 2022 Findings)</b>, Abu Dhabi, 2022.12</li>

<li> <a href="https://jiacheng-ye.github.io/">Jiacheng Ye</a>*, <a href="https://sumilergao.github.io/jiahuig.hku/">Jiahui Gao</a>*, <a href="https://qtli.github.io/">Qintong Li</a>, <a href="https://xuhangcn.github.io/">Hang Xu</a>, <a href="https://jiangtaofeng.github.io/">Jiangtao Feng</a>, <a href="https://lividwo.github.io/zywu.github.io/">Zhiyong Wu</a>, <a href="https://taoyds.github.io">Tao Yu</a>, and Lingpeng Kong, <strong><a href=https://arxiv.org/abs/2202.07922> ZeroGen: Efficient Zero-shot Learning via Dataset Generation</a></strong>, In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing</em> <b>(EMNLP 2022)</b>, Abu Dhabi, 2022.12</li>

<li> <a href="https://tianbaoxie.com/">Tianbao Xie</a>*, <a href="https://scholar.google.com/citations?user=WFKit_4AAAAJ">Chen Henry Wu</a>*, <a href="https://scholar.google.com.sg/citations?user=XTbDLrkAAAAJ">Peng Shi</a>, <a href="https://ruiqi-zhong.github.io/">Ruiqi Zhong</a>, Torsten Scholak, Michihiro Yasunaga, Chien-Sheng Wu, <a href="https://maszhongming.github.io/">Ming Zhong</a>, <a href="https://pcyin.me/">Pengcheng Yin</a>, <a href="http://www.sidaw.xyz/">Sida Wang</a>, <a href="https://www.victorzhong.com/">Victor Zhong</a>, Bailin Wang, <a href="https://scholar.google.com/citations?user=t_Bwt70AAAAJ">Chengzu Li</a>, Connor Boyle, Ansong Ni, Ziyu Yao, <a href="http://www.cs.yale.edu/homes/radev/">Dragomir Radev</a>, <a href="http://cmxiong.com/">Caiming Xiong</a>, Lingpeng Kong, <a href="https://ryanzhumich.github.io/">Rui Zhang</a>, <a href="https://homes.cs.washington.edu/~nasmith/">Noah A. Smith</a>, <a href="https://www.cs.washington.edu/people/faculty/lsz">Luke Zettlemoyer</a>, and <a href="https://taoyds.github.io">Tao Yu</a>, <strong><a href="https://arxiv.org/abs/2201.05966"> UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models</a></strong>, In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing</em> <b>(EMNLP 2022)</b>, Abu Dhabi, 2022.12</li>

<li> <a href="https://github.com/Doraemonzzz">Zhen Qin</a>, Xiaodong Han, <a href="https://cs.anu.edu.au/people/weixuan-sun">Weixuan Sun</a>, <a href="https://dxli94.github.io/">Dongxu Li</a>, Lingpeng Kong, <a href="http://users.cecs.anu.edu.au/~nmb/">Nick Barnes</a>, and <a href="https://yiranzhong.com/">Yiran Zhong</a>, <strong><a href="https://arxiv.org/abs/2210.10340">The Devil in Linear Transformer</a></strong>, In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing</em> <b>(EMNLP 2022)</b>, Abu Dhabi, 2022.12</li>

<li> <a href="https://scholar.google.com/citations?user=IxrYJ6EAAAAJ">Changlong Yu</a>, Tianyi Xiao, Lingpeng Kong, <a href="https://www.cse.ust.hk/~yqsong/">Yangqiu Song</a>, and <a href="https://cse.hkust.edu.hk/~wilfred/">Wilfred Ng</a>, <strong><a href="https://arxiv.org/abs/2210.13002">An Empirical Revisiting of Linguistic Knowledge Fusion in Language Understanding Tasks</a></strong>, In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing</em> <b>(EMNLP 2022)</b>, Abu Dhabi, 2022.12</li>

<li> <a href="https://scholar.google.com/citations?user=fY69CxIAAAAJ">Chenxin An</a>, <a href="https://jiangtaofeng.github.io/">Jiangtao Feng</a>, Kai Lv, Lingpeng Kong, <a href="https://xpqiu.github.io/en.html">Xipeng Qiu</a>, and <a href="https://nlp.fudan.edu.cn/28702/list.htm">Xuanjing Huang</a>, <strong><a href="https://arxiv.org/abs/2205.14690">CoNT: Contrastive Neural Text Generation</a></strong>, In <em>Advances in Neural Information Processing Systems</em> <b>(NeurIPS 2022)</b>, New Orleans, Louisiana, 2022.11 <b>[Spotlight]</b></li>

<li> <a href="https://yxuansu.github.io/">Yixuan Su</a>, Tian Lan, <a href="https://libertywing.github.io/yanwang.github.io/">Yan Wang</a>,  <a href="https://dyogatama.github.io/">Dani Yogatama</a>, Lingpeng Kong, and <a href="https://sites.google.com/site/nhcollier/">Nigel Collier</a>, <strong><a href="https://arxiv.org/abs/2202.06417">A Contrastive Framework for Neural Text Generation</a></strong>, In <em>Advances in Neural Information Processing Systems</em> <b>(NeurIPS 2022)</b>, New Orleans, Louisiana, 2022.11 <b>[Spotlight]</b></li>

<li> <a href="https://cn.linkedin.com/in/jinxing-zhou-26a77916b">Jinxing Zhou</a>, <a href="https://jytime.github.io/">Jianyuan Wang</a>, <a href="https://www.researchgate.net/profile/Jiayi-Zhang-18">Jiayi Zhang</a>, <a href="https://cs.anu.edu.au/people/weixuan-sun">Weixuan Sun</a>, <a href="https://jingzhang617.github.io/">Jing Zhang</a>, <a href="https://cecas.clemson.edu/~stb/">Stan Birchfield</a>, <a href="https://scholar.google.com/citations?user=DsEONuMAAAAJ&hl=zh-CN">Dan Guo</a>, Lingpeng Kong, <a href="https://sites.google.com/view/meng-wang/home">Meng Wang</a>, and <a href="https://yiranzhong.com/">Yiran Zhong</a>, <strong><a href="https://arxiv.org/abs/2207.05042">Audio-Visual Segmentation</a></strong>,  In <em>Proceedings of the European Conference on Computer Vision</em> <b>(ECCV 2022)</b>, 2022.10 </li>

<li> <a href="https://lzhengisme.github.io/">Lin Zheng</a>, <a href="https://chongw.github.io/">Chong Wang</a>, and Lingpeng Kong, <strong><a href=https://arxiv.org/abs/2204.04667> Linear Complexity Randomized Self-attention Mechanism</a></strong>, In <em>Proceedings of the International Conference on Machine Learning</em> <b>(ICML 2022)</b>, 2022.7</li>

<li> <a href="https://lzhengisme.github.io/">Lin Zheng</a>, <a href="https://hk.linkedin.com/in/huijie-pan-8a0a871a4">Huijie Pan</a>, and Lingpeng Kong, <strong><a href=https://arxiv.org/abs/2110.02453> Ripple Attention for Visual Perception with Sub-quadratic Complexity</a></strong>, In <em>Proceedings of the International Conference on Machine Learning</em> <b>(ICML 2022)</b>, 2022.7</li>

<li><a href="https://prange.jakob.georgetown.domains/">Jakob Prange</a>, <a href="http://people.cs.georgetown.edu/nschneid/">Nathan Schneider</a>, and Lingpeng Kong, <strong><a href="https://arxiv.org/pdf/2112.07874.pdf">Linguistic Frameworks Go Toe-to-Toe at Neuro-Symbolic Language Modeling</a></strong>, In <em>Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics</em> <b>(NAACL 2022)</b>, 2022.7 </li>

<li><a href="https://qtli.github.io/">Qintong Li</a>, <a href="https://lipiji.com/">Piji Li</a>, <a href="https://scholar.google.com/citations?user=aSJcgQMAAAAJ">Wei Bi</a>, <a href="https://ir.sdu.edu.cn/~zhaochunren/">Zhaochun Ren</a>, <a href="https://scholar.google.com.hk/citations?user=oKbXK7EAAAAJ">Yuxuan Lai</a>, and Lingpeng Kong, <strong><a href="https://arxiv.org/pdf/2204.09453.pdf">Event Transition Planning for Open-ended Text Generation</a></strong>, In <em>Findings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2022 Findings)</b>, 2022.5 </li>

<li><a href="https://lividwo.github.io/zywu.github.io/">Zhiyong Wu</a>, <a href="https://scholar.google.com/citations?user=aSJcgQMAAAAJ">Wei Bi</a>, <a href="https://lixiang3776.github.io/">Xiang Li</a>, Lingpeng Kong, and <a href="https://www.cs.hku.hk/people/academic-staff/kao">Ben Kao</a>, <strong><a href="https://arxiv.org/abs/2205.01941">Lexical Knowledge Internalization for Neural Dialog Generation</a></strong>, In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2022)</b>, 2022.5 </li>

<li><a href="https://homes.cs.washington.edu/~hapeng/">Hao Peng</a>, <a href="https://homes.cs.washington.edu/~jkasai/">Jungo Kasai</a>, <a href="https://nik0spapp.github.io/">Nikolaos Pappas</a>, <a href="https://dyogatama.github.io/">Dani Yogatama</a>, <a href="https://zhaofengwu.github.io/">Zhaofeng Wu</a>, Lingpeng Kong, <a href="https://schwartz-lab-huji.github.io/">Roy Schwartz</a>, and <a href="https://homes.cs.washington.edu/~nasmith/">Noah A. Smith</a>, <strong><a href="https://arxiv.org/abs/2110.02488">ABC: Attention with Bounded-memory Control</a></strong>, In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2022)</b>, 2022.5 </li>

<li> <a href="https://github.com/Doraemonzzz">Zhen Qin</a>, <a href="https://cs.anu.edu.au/people/weixuan-sun">Weixuan Sun</a>, <a href="https://www.researchgate.net/profile/Hui-Deng-24">Hui Deng</a>, <a href="https://dxli94.github.io/">Dongxu Li</a>, <a href="https://www.zhihu.com/people/wei-yun-shen">Yunshen Wei</a>, <a href="https://github.com/lkjx82">Baohong Lv</a>, <a href="https://yan-junjie.github.io/">Junjie Yan</a>, Lingpeng Kong, and <a href="https://yiranzhong.com/">Yiran Zhong</a>, <strong><a href="https://openreview.net/pdf?id=Bl8CQrx2Up4">cosFormer: Rethinking Softmax In Attention</a></strong>,  In <em>International Conference on Learning Representations</em> <b>(ICLR 2022)</b>, 2022.4 </li>

<li> <a href="https://han-shi.github.io/">Han Shi</a>*, <a href="https://sumilergao.github.io/jiahuig.hku/">Jiahui Gao</a>*, <a href="https://scholar.google.com/citations?user=J_8TX6sAAAAJ&hl=en">Hang Xu</a>, <a href="https://lemondan.github.io/">Xiaodan Liang</a>, <a href="https://www.ee.columbia.edu/~zgli/">Zhenguo Li</a>, Lingpeng Kong, <a href="https://saasweb.hku.hk/staff/smslee/">Stephen M. S. Lee</a>, and <a href="https://www.cse.ust.hk/~jamesk/">James Kwok</a>, <strong><a href="https://openreview.net/pdf?id=dUV91uaXm3">Revisiting Over-smoothing in BERT from the Perspective of Graph</a></strong>,  In <em>International Conference on Learning Representations</em> <b>(ICLR 2022)</b>, 2022.4 <b>[Spotlight]</b></li>

</ul>
<h3>2021</h3>
<ul>
<li><a href="https://lzhengisme.github.io/">Lin Zheng</a>, <a href="https://lividwo.github.io/zywu.github.io/">Zhiyong Wu</a> and Lingpeng Kong, <strong><a href="https://arxiv.org/abs/2105.14850">Cascaded Head-colliding Attention</a></strong>, In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2021)</b>, 2021.8 </li>
<li><a href="https://lividwo.github.io/zywu.github.io/">Zhiyong Wu</a>, Lingpeng Kong, <a href="https://scholar.google.com/citations?user=aSJcgQMAAAAJ">Wei Bi</a>, <a href="https://lixiang3776.github.io/">Xiang Li</a> and <a href="https://www.cs.hku.hk/people/academic-staff/kao">Ben Kao</a>, <strong><a href="https://arxiv.org/abs/2105.14462">Good for Misconceived Reasons: An Empirical Revisiting on the Need for Visual Context in Multimodal Machine Translation</a></strong>, In <em>Proceedings of the Annual Meeting of the Association for Computational Linguistics</em> <b>(ACL 2021)</b>, 2021.8 </li>
<li><a href="https://dyogatama.github.io/">Dani Yogatama</a>, <a href="https://scholar.google.com/citations?user=vcmTSYEAAAAJ">Cyprien de Masson d'Autume</a>, and Lingpeng Kong, <strong><a href=https://dyogatama.github.io/publications_files/Yogatama+etal_TACL2021.pdf>Adaptive Semiparametric Language Models</a></strong>, <em>Transactions of the Association for Computational Linguistics</em> <b>(TACL)</b>, 2021</li>
<li><a href="https://homes.cs.washington.edu/~hapeng/">Hao Peng</a>, <a href="https://nik0spapp.github.io/">Nikolaos Pappas</a>, <a href="https://dyogatama.github.io/">Dani Yogatama</a>, <a href="https://schwartz-lab-huji.github.io/">Roy Schwartz</a>, <a href="https://homes.cs.washington.edu/~nasmith/">Noah A. Smith</a>, and Lingpeng Kong, <strong><a href=https://openreview.net/forum?id=QtTKTdVrFBB>Random Feature Attention</a></strong>,  In <em>International Conference on Learning Representations</em> <b>(ICLR 2021)</b>, Vienna, Austria, 2021.5 <b>[Spotlight]</b></li>
</ul>
<h3>2020</h3>
<ul>
<li><a href="https://www.cs.cmu.edu/~akuncoro/">Adhiguna Kuncoro</a>*, Lingpeng Kong*, <a href="https://dpfried.github.io/">Daniel Fried</a>*, <a href="https://dyogatama.github.io/">Dani Yogatama</a>, <a href="https://scholar.google.com/citations?user=bMTBja0AAAAJ&hl=en">Laura Rimell</a>, <a href="http://www.cs.cmu.edu/~cdyer/">Chris Dyer</a>, and <a href="https://www.cs.ox.ac.uk/people/phil.blunsom/">Phil Blunsom</a>, <strong><a href=https://arxiv.org/pdf/2005.13482.pdf>Syntactic Structure Distillation Pretraining For Bidirectional Encoders</a></strong>, <em>Transactions of the Association for Computational Linguistics</em> <b>(TACL)</b>, 2020.9</li>
<li><a href="https://www.cs.ox.ac.uk/people/lei.yu/">Lei Yu</a>, Laurent Sartran, Wojciech Stokowiec, <a href="https://www.cs.cmu.edu/~lingwang/">Wang Ling</a>, Lingpeng Kong, <a href="https://www.cs.ox.ac.uk/people/phil.blunsom/">Phil Blunsom</a>, and <a href="http://www.cs.cmu.edu/~cdyer/">Chris Dyer</a>, <strong><a href=https://arxiv.org/pdf/1910.00553.pdf>Better Document-level Machine Translation with Bayes' Rule</a></strong>, <em>Transactions of the Association for Computational Linguistics</em> <b>(TACL)</b>, 2020.4</li>
<li>Lingpeng Kong, <a href="https://scholar.google.com/citations?user=vcmTSYEAAAAJ">Cyprien de Masson d'Autume</a>, <a href="https://www.cs.cmu.edu/~lingwang/">Wang Ling</a>, <a href="https://www.cs.ox.ac.uk/people/lei.yu/">Lei Yu</a>, <a href="https://zihangdai.github.io/">Zihang Dai</a>, and <a href="https://dyogatama.github.io/">Dani Yogatama</a>, <strong><a href=https://arxiv.org/abs/1910.08350.pdf>A Mutual Information Maximization Perspective of Language Representation Learning</a></strong>, In <em>International Conference on Learning Representations</em> <b>(ICLR 2020)</b>, Ethiopia, 2020.4 <b>[Spotlight]</b></li>
</ul>
<h3>2019</h3>
<ul>
<li><a href="https://scholar.google.com/citations?user=vcmTSYEAAAAJ">Cyprien de Masson d'Autume</a>, <a href="https://ruder.io/">Sebastian Ruder</a>, Lingpeng Kong, and <a href="https://dyogatama.github.io/">Dani Yogatama</a>, <strong><a href=https://arxiv.org/pdf/1906.01076.pdf> Episodic Memory in Lifelong Language Learning</a></strong>, In <em>Advances in Neural Information Processing Systems</em> <b>(NeurIPS 2019)</b>, Vancouver, Canada, 2019.11</li>
<li>Lingpeng Kong, Gabor Melis, <a href="https://www.cs.cmu.edu/~lingwang/">Wang Ling</a>, <a href="https://www.cs.ox.ac.uk/people/lei.yu/">Lei Yu</a>, and <a href="https://dyogatama.github.io/">Dani Yogatama</a>, <strong><a href=https://arxiv.org/pdf/1901.09296.pdf>Variational Smoothing in Recurrent Neural Network Language Models</a></strong>, In <em>International Conference on Learning Representations</em> <b>(ICLR 2019)</b>, New Orleans, Louisiana, 2019.5</li>
<li><a href="https://dyogatama.github.io/">Dani Yogatama</a>, <a href="https://scholar.google.com/citations?user=vcmTSYEAAAAJ">Cyprien de Masson d'Autume</a>, Jerome Connor, <a href="http://www.tomas.kocisky.eu/">Tomas Kocisky</a>, Mike Chrzanowski, Lingpeng Kong, <a href="http://angelikilazaridou.github.io/">Angeliki Lazaridou</a>, <a href="https://www.cs.cmu.edu/~lingwang/">Wang Ling</a>, <a href="https://www.cs.ox.ac.uk/people/lei.yu/">Lei Yu</a>, <a href="http://www.cs.cmu.edu/~cdyer/">Chris Dyer</a>, and <a href="https://www.cs.ox.ac.uk/people/phil.blunsom/">Phil Blunsom</a>, <strong><a href=https://arxiv.org/pdf/1901.11373.pdf>Learning and Evaluating General Linguistic Intelligence</a></strong>, <em>arXiv:1901.11373</em>, 2019.2</li>
</ul>
<h3>2018</h3>
<ul>
<li> Jiangtao Feng, Lingpeng Kong, <a href="https://posenhuang.github.io/">Po-Sen Huang</a>, <a href="https://chongw.github.io/">Chong Wang</a>, Da Huang, <a href="https://jiayuanm.com/">Jiayuan Mao</a>, Kan Qiao, and <a href="https://dennyzhou.github.io/">Dengyong Zhou</a>, <strong><a href=https://arxiv.org/pdf/1811.02172.pdf> Neural Phrase-to-Phrase Machine Translation</a></strong>, <em>arXiv:1811.02172</em>, 2018.11</li>
<li> <a href="https://www.cs.ox.ac.uk/people/lei.yu/">Lei Yu</a>, <a href="https://scholar.google.com/citations?user=vcmTSYEAAAAJ">Cyprien de Masson d'Autume</a>, <a href="http://www.cs.cmu.edu/~cdyer/">Chris Dyer</a>, <a href="https://www.cs.ox.ac.uk/people/phil.blunsom/">Phil Blunsom</a>, Lingpeng Kong, and <a href="https://www.cs.cmu.edu/~lingwang/">Wang Ling</a>, <strong><a href=https://arxiv.org/pdf/1811.10475.pdf>Sentence Encoding with Tree-constrained Relation Networks</a></strong>, <em>arXiv:1811.10475</em>, 2018.11</li>
</ul>
<h3> 2017 </h3>
<ul>
<li> Lingpeng Kong, <strong><a href="thesis_draft.pdf">Neural Representation Learning in Linguistic Structured Prediction</a></strong>, Ph.D. thesis, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, 2017.9</li>
<li> <a href="http://people.csail.mit.edu/haotang/">Hao Tang</a>, Liang Lu, Lingpeng Kong, <a href="https://home.ttic.edu/~kgimpel/">Kevin Gimpel</a>, <a href="https://home.ttic.edu/~klivescu/">Karen Livescu</a>, <a href="http://www.cs.cmu.edu/~cdyer/">Chris Dyer</a>, <a href="https://homes.cs.washington.edu/~nasmith/">Noah A. Smith</a>, and <a href="https://www.inf.ed.ac.uk/people/staff/Stephen_Renals.html">Steve Renals</a>, <strong><a href="https://arxiv.org/abs/1708.00531">End-to-End Neural Segmental Models for Speech Recognition</a></strong>, <em>IEEE Journal of Selected Topics in Signal Processing</em>, 2017.8</li>
<li> Liang Lu, Lingpeng Kong, <a href="http://www.cs.cmu.edu/~cdyer/">Chris Dyer</a>, and <a href="https://homes.cs.washington.edu/~nasmith/">Noah A. Smith</a>, <strong><a href="https://arxiv.org/abs/1702.06378">Multi-task Learning with CTC and Segmental CRF for Speech Recognition</a></strong>, In <em>Proceedings of the Annual Conference of the International Speech Communication Association</em> <b>(INTERSPEECH 2017)</b>, Stockholm, Sweden, 2017.8</li>
<li> <a href="https://www.cs.cmu.edu/~akuncoro/">Adhiguna Kuncoro</a>, <a href="http://miguelballesteros.com/">Miguel Ballesteros</a>, Lingpeng Kong, <a href="http://www.cs.cmu.edu/~cdyer/">Chris Dyer</a>, <a href="http://www.phontron.com/">Graham Neubig</a>, and <a href="https://homes.cs.washington.edu/~nasmith/">Noah A. Smith</a>, <strong><a href="https://arxiv.org/abs/1611.05774">What Do Recurrent Neural Network Grammars Learn About Syntax?</a></strong>, In <em>Proceedings of the Conference of the European Chapter of the Association for Computational Linguistics</em> <b>(EACL 2017)</b>, Valencia, Spain, 2017.4 <b>[Outstanding Paper Award]</b></li>
<li> Chris Alberti, Daniel Andor, Ivan Bogatyy, <a href="http://www.cs.columbia.edu/~mcollins/">Michael Collins</a>, Dan Gillick, Lingpeng Kong, <a href="https://people.csail.mit.edu/maestro/">Terry Koo</a>, Ji Ma, Mark Omernick, <a href="https://www.petrovi.de/">Slav Petrov</a>, Chayut Thanapirom, Zora Tung, and David Weiss, <strong><a href="https://arxiv.org/abs/1703.04929">SyntaxNet Models for the CoNLL 2017 Shared Task</a></strong>, <em>arXiv:1703.04929</em>, 2017.3</li>
<li> Lingpeng Kong, Chris Alberti, Daniel Andor, Ivan Bogatyy, and David Weiss, <strong><a href="https://arxiv.org/abs/1703.04474">DRAGNN: A Transition-based Framework for Dynamically Connected Neural Networks</a></strong>, <em>arXiv:1703.04474</em>, 2017.3</li>
<li> <a href="http://www.phontron.com/">Graham Neubig</a>, <a href="http://www.cs.cmu.edu/~cdyer/">Chris Dyer</a>, <a href="https://u.cs.biu.ac.il/~yogo/">Yoav Goldberg</a>, Austin Matthews, <a href="https://wammar.github.io/">Waleed Ammar</a>, Antonios Anastasopoulos, <a href="http://miguelballesteros.com/">Miguel Ballesteros</a>, <a href="https://www3.nd.edu/~dchiang/">David Chiang</a>, Daniel Clothiaux, <a href="https://people.eng.unimelb.edu.au/tcohn/">Trevor Cohn</a>, <a href="http://cs.jhu.edu/~kevinduh/">Kevin Duh</a>, <a href="https://www.manaalfaruqui.com/">Manaal Faruqui</a>, Cynthia Gan, <a href="http://www.dhgarrette.com/">Dan Garrette</a>, <a href="https://yangfengji.net/">Yangfeng Ji</a>, Lingpeng Kong, <a href="https://www.cs.cmu.edu/~akuncoro/">Adhiguna Kuncoro</a>, Gaurav Kumar, Chaitanya Malaviya, Paul Michel, Yusuke Oda, Matthew Richardson, Naomi Saphra, <a href="https://swabhs.com/">Swabha Swayamdipta</a>, and <a href="http://pcyin.me/">Pengcheng Yin</a>, <strong><a href="https://arxiv.org/abs/1701.03980">DyNet: The Dynamic Neural Network Toolkit</a></strong>, <em>arXiv:1701.03980</em>, 2017.1</li>
</ul>
<h3>2016</h3>
<ul>
<li> <a href="https://www.cs.cmu.edu/~akuncoro/">Adhiguna Kuncoro</a>, <a href="http://miguelballesteros.com/">Miguel Ballesteros</a>, Lingpeng Kong, <a href="http://www.cs.cmu.edu/~cdyer/">Chris Dyer</a>, and <a href="https://homes.cs.washington.edu/~nasmith/">Noah A. Smith</a>, <strong><a href="https://arxiv.org/abs/1609.07561">Distilling an Ensemble of Greedy Dependency Parsers into One MST Parser</a></strong>, In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing</em> <b>(EMNLP 2016)</b>, Austin, TX, 2016.11</li>
<li> Liang Lu*, Lingpeng Kong*, <a href="http://www.cs.cmu.edu/~cdyer/">Chris Dyer</a>, <a href="https://homes.cs.washington.edu/~nasmith/">Noah A. Smith</a>, and Steve Renals, <strong><a href="http://arxiv.org/abs/1603.00223">Segmental Recurrent Neural Networks for End-to-end Speech Recognition</a></strong>, In <em>Proceedings of the Annual Conference of the International Speech Communication Association</em> <b>(INTERSPEECH 2016)</b>, San Francisco, California, 2016.9 (*equal contribution)</li>
<li> Lingpeng Kong, <a href="http://www.cs.cmu.edu/~cdyer/">Chris Dyer</a>, and <a href="https://homes.cs.washington.edu/~nasmith/">Noah A. Smith</a>, <strong><a href="http://arxiv.org/abs/1511.06018">Segmental Recurrent Neural Networks</a></strong>, In <em>International Conference on Learning Representations</em> <b>(ICLR 2016)</b>, San Juan, Puerto Rico, 2016.5</li>
<li> <a href="https://yangfengji.net/">Yangfeng Ji</a>, <a href="https://people.eng.unimelb.edu.au/tcohn/">Trevor Cohn</a>, Lingpeng Kong, <a href="http://www.cs.cmu.edu/~cdyer/">Chris Dyer</a>, and <a href="https://jacobeisenstein.github.io/">Jacob Eisenstein</a>, <strong><a href="http://arxiv.org/abs/1511.03962">Document Context Language Models</a></strong>, In <em>International Conference on Learning Representations</em> <b>(ICLR 2016 Workshop Track)</b>, San Juan, Puerto Rico, 2016.5</li>
</ul>
<h3>2015</h3>
<ul>
<li> <a href="https://dyogatama.github.io/">Dani Yogatama</a>, Lingpeng Kong, and <a href="https://homes.cs.washington.edu/~nasmith/">Noah A. Smith</a>, <strong><a href="paper/emnlp15.pdf">Bayesian Optimization of Text Representations</a></strong>, In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing</em> <b>(EMNLP 2015)</b>, Lisboa, Portugal, 2015.9</li> 
<li> <a href="https://crowd.ist.psu.edu/">Ting-Hao (Kenneth) Huang</a>, <a href="https://www.csie.ntu.edu.tw/~yvchen/">Yun-Nung Chen</a>, and Lingpeng Kong, <strong><a href="paper/sighan15.pdf">ACBiMA: Advanced Chinese Bi-Character Word Morphological Analyzer</a></strong>, In <em>Proceedings of The 8th SIGHAN Workshop on Chinese Language Processing</em> <b>(SIGHAN-8)</b>, Beijing, China, 2015.7 [<a href="http://acbima.org/">software</a>]</li>
<li> Lingpeng Kong, <a href="http://rush-nlp.com/">Alexander M. Rush</a>, and <a href="https://homes.cs.washington.edu/~nasmith/">Noah A. Smith</a>, <strong><a href="paper/naacl15.pdf">Transforming Dependencies into Phrase Structures</a></strong>, In <em>Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics - Human Language Technologies</em> <b>(NAACL-HLT 2015)</b>, Denver, CO, 2015.5 [<a href="https://github.com/ikekonglp/PAD">software</a>]</li>
</ul>
<h3>2014</h3>
<ul>
<li> Lingpeng Kong, <a href="http://people.cs.georgetown.edu/nschneid/">Nathan Schneider</a>, <a href="https://swabhs.com/">Swabha Swayamdipta</a>, Archna Bhatia, <a href="http://www.cs.cmu.edu/~cdyer/">Chris Dyer</a>, and <a href="https://homes.cs.washington.edu/~nasmith/">Noah A. Smith</a>, <strong><a href="paper/emnlp14a.pdf">A Dependency Parser for Tweets</a></strong>, In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing</em> <b>(EMNLP 2014)</b>, Doha, Qatar, 2014.10  [<a href="material/tweeboparserpdf.pdf">slides</a>, <a href="http://www.ark.cs.cmu.edu/TweetNLP/">software</a>] </li>

<li> <a href="https://sites.cs.ucsb.edu/~william/">William Yang Wang</a>, Lingpeng Kong, Kathryn Mazaitis, and <a href="http://www.cs.cmu.edu/~wcohen/">William W. Cohen</a>, <strong><a href="paper/emnlp14b.pdf">Dependency Parsing for Weibo: An Efficient Probabilistic Logic Programming Approach</a></strong>, In <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing</em> <b>(EMNLP 2014)</b>, Doha, Qatar, 2014.10 </li>
<li>Lingpeng Kong and <a href="https://homes.cs.washington.edu/~nasmith/">Noah A. Smith</a>, <strong><a href="http://arxiv.org/abs/1404.4314">An Empirical Comparison of Parsing Methods for Stanford Dependencies</a></strong>, <em>arXiv:1404.4314</em>, 2014.04 </li>
</ul>
<h3>2011</h3>
<ul>
<li>Lingpeng Kong and Likun Qiu, <strong><a href="paper/ialp11a.pdf">Formalization and Rules for Recognition of Satirical Irony</a></strong>, In <em>Proceedings of the International Conference on Asian Language Processing</em>, Penang, Malaysia, 2011.11 </li>

<li>Likun Qiu, Lei Wu, Changjian Hu, Kai Zhao, and Lingpeng Kong, <strong><a href="paper/ialp11b.pdf">Improving Chinese Dependency Parsing with Self-Disambiguating Patterns</a></strong>, In <em>Proceedings of the International Conference on Asian Language Processing</em>, Penang, Malaysia, 2011.11 </li></ul>

</ul>

</section>
</body>
</html>

